{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "975bf095-aa29-41fa-8ad3-29773153d4fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\program files\\python38\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\program files\\python38\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\program files\\python38\\lib\\site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\program files\\python38\\lib\\site-packages (from nltk) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in c:\\program files\\python38\\lib\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\program files\\python38\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1 -> 24.2\n",
      "[notice] To update, run: C:\\Program Files\\Python38\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tabulate\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Installing collected packages: tabulate\n",
      "Successfully installed tabulate-0.9.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1 -> 24.2\n",
      "[notice] To update, run: C:\\Program Files\\Python38\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "!pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e70571f4-f67d-4209-b2a3-2ddd054b5218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------------+----------------------------------+--------------------+\n",
      "|   AvgWordLen |   AvgSentenceLen |   no.ofTimesEachWordAppearsOnAvg | FileName           |\n",
      "+==============+==================+==================================+====================+\n",
      "|            4 |               16 |                                1 | TTS.py             |\n",
      "+--------------+------------------+----------------------------------+--------------------+\n",
      "|            4 |                6 |                                1 | doc1.txt           |\n",
      "+--------------+------------------+----------------------------------+--------------------+\n",
      "|            3 |                6 |                                1 | doc2.txt           |\n",
      "+--------------+------------------+----------------------------------+--------------------+\n",
      "|            4 |               16 |                                1 | male.txt           |\n",
      "+--------------+------------------+----------------------------------+--------------------+\n",
      "|            6 |                8 |                                1 | p2acorpus.py       |\n",
      "+--------------+------------------+----------------------------------+--------------------+\n",
      "|            5 |               12 |                                1 | p2b_ownCorpus.py   |\n",
      "+--------------+------------------+----------------------------------+--------------------+\n",
      "|            5 |               16 |                                1 | pisoundtospeech.py |\n",
      "+--------------+------------------+----------------------------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus.reader import PlaintextCorpusReader\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Step 1: Create a Plaintext Corpus\n",
    "\n",
    "# Directory where the corpus files are located\n",
    "corpus_root = 'my_corpus'  # Change this to your directory name\n",
    "if not os.path.exists(corpus_root):\n",
    "    os.makedirs(corpus_root)\n",
    "\n",
    "# Sample documents (You can add more files here)\n",
    "documents = {\n",
    "    'TTS.py': \"NLTK is a leading platform for building Python programs to work with human language data.\",\n",
    "    'male.txt': \"It provides easy-to-use interfaces to over 50 corpora and lexical resources.\",\n",
    "    'pisoundtospeech.py': \"NLTK includes libraries for text processing, classification, tokenization, stemming, and more.\",\n",
    "    'p2acorpus.py': \"Python provides various libraries for corpus processing.\",\n",
    "    'p2b_ownCorpus.py': \"Creating your own corpus allows for customized text processing and analysis.\"\n",
    "}\n",
    "\n",
    "# Save each document as a text file in the corpus directory\n",
    "for file_name, content in documents.items():\n",
    "    with open(os.path.join(corpus_root, file_name), 'w') as f:\n",
    "        f.write(content)\n",
    "\n",
    "# Create a PlaintextCorpusReader\n",
    "corpus = PlaintextCorpusReader(corpus_root, '.*')\n",
    "\n",
    "# Step 2: Calculate the required statistics for each file\n",
    "\n",
    "table_data = []\n",
    "\n",
    "for fileid in corpus.fileids():\n",
    "    words = corpus.words(fileid)\n",
    "    sents = corpus.sents(fileid)\n",
    "    \n",
    "    avg_word_len = sum(len(word) for word in words) // len(words)\n",
    "    avg_sentence_len = sum(len(sent) for sent in sents) // len(sents)\n",
    "    word_freq = nltk.FreqDist(words)\n",
    "    avg_word_freq = sum(word_freq.values()) // len(word_freq)\n",
    "\n",
    "    table_data.append([avg_word_len, avg_sentence_len, avg_word_freq, fileid])\n",
    "\n",
    "# Print the table with the required format\n",
    "headers = [\"AvgWordLen\", \"AvgSentenceLen\", \"no.ofTimesEachWordAppearsOnAvg\", \"FileName\"]\n",
    "print(tabulate(table_data, headers=headers, tablefmt=\"grid\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306a5328-8331-4551-89e9-f912c7ad6833",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
